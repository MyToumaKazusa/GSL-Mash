# GSL-Mash
My code is built on SMRB https://github.com/ssnowyu/SMRB
Dataet also be seen there

# Project Structure
The directory structure of new project looks like this:


    │   README.md
    │   requirements.txt               <- File for installing python dependencies
    │   setup.cfg                      <- Configuration of linters and pytest
    │   test.py                        <- Run testing
    │   train.py                       <- Run training
    │
    ├───configs                        <- Hydra configuration files
    │   │   test.yaml                     <- Main config for testing
    │   │   train.yaml                    <- Main config for training
    │   │
    │   ├───callbacks                  <- Lightning callbacks
    │   │       wandb.yaml                <- Wandb and metrics callbacks
    │   │
    │   ├───datamodule                    
    │   │       partial_text_bert.yaml    <- Partial text-based dataset embedded by BERT configs
    │   │       partial_word_bert.yaml    <- Partial word-based dataset embedded by BERT configs
    │   │
    │   ├───experiment                 <- Experiment configs
    │   │
    │   ├───hparams_search             <- Hyperparameter search configs
    │   │
    │   ├───logger                     <- Logger configs
    │   │
    │   ├───log_dir                    <- Logging directory configs
    │   │
    │   ├───model                      <- Model configs
    │   │
    │   └───trainer                    <- Trainer configs
    │
    ├───data                        <- Project data
    │
    ├───logs                        <- Logs generated by Hydra and PyTorch 
                                       Lightning loggers
    ├───src                         <- Source code
    │   │   testing_pipeline.py
    │   │   training_pipeline.py
    │   │
    │   ├───callbacks
    │   │       wandb_callbacks.py
    │   │
    │   ├───datamodules             <- Lightning datamodules
    │   │
    │   ├───models                  <- Lightning models
    │   │
    │   ├───utils                   <- Utility scripts
    │   │
    │   └───vendor                  <- Third party code that cannot be installed using PIP/Conda
    │
    └───tests                       <- Tests of any kind
        │
        ├───helpers                    <- A couple of testing utilities
        │
        ├───shell                      <- Shell/command based tests
        │
        └───unit                       <- Unit tests


# Installation

You can install environment by anaconda, and then download the dataset.

## Install with anaconda

    # clone project
    git clone https://github.com/MyToumaKazusa/GSL-Mash
    cd GSL-Mash

## Create conda environment
    conda create -n gsl-mash python=3.10
    conda activate gsl-mash

## Install requirements
    pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116
    conda install pip==24.0
    pip install -r requirements.txt
    pip install torchmetrics==0.9.1
    wget https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.0%2Bpt113cu116-cp310-cp310-linux_x86_64.whl
    wget https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.15%2Bpt113cu116-cp310-cp310-linux_x86_64.whl
    wget https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp310-cp310-linux_x86_64.whl
    # Remember to install the wheels built by wget
    # If you are not using Linux, search this website for your packages
    # https://pytorch-geometric.com/whl/torch-1.13.1%2Bcu116.html

# Quickstart
Implement the DL-based model as the LightningModule class. Details refer to Model Implementation. Here the GSL-Mash model (pre-configured in our project) is used as an example.

Write a configuration file called simple_model for your model.

     _target_: src.models.GSL-Mash.GSL_MASH

    data_dir: ${data_dir}/api_mashup
    api_embed_path: embeddings/partial/text_bert_api_embeddings.npy
    mashup_embed_channels: 300
    mlp_output_channels: 300
    weight_decay: 0.00001
     
Write a configuration file called mlp for your experiment.

    _target_: src.datamodules.mashup_datamodule_new.MashupDataModule

    data_dir: ${data_dir}/api_mashup
    num_candidates: 932
    mashup_path: embeddings/text_bert_mashup_embeddings.npy
    api_path: embeddings/partial/text_bert_api_embeddings.npy
    invoked_path: partial_invocation.pkl
    pair_in_training: true
    negative_samples_ratio: 5

    train_val_test_split: [3190, 912, 455] # 7: 2: 1
    batch_size: 64 #SMRBgsl 16
    num_workers: 12
    pin_memory: true 

Since the project uses wandb as the log framework by default, you will need to have a wandb account and bind the account to the project by executing the following command.

    wandb login
This command needs to be executed only once during the entire development process.

If you do not want to use wandb, you can also choose another log framework. Please refer to LightningModule for how to change it.

run the project.

    python train.py experiment=gsl-mash/partial_bert

